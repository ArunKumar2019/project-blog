public BatchGenericModel process(BatchGenericModel item, String jobName,
			NamedParameterJdbcTemplate namedJdbcTemplate, JobConfigModel jobConfig) throws CstBatchException {

		BL_ACCT_BL_TYP_SQL = "SELECT BL_TYP_STAT_CD, BL_TYP_EFF_DT, BILL_SYS_ID FROM " + jobConfig.getSchemaName()
				+ "BL_ACCT WHERE CUST_ID_NO = :custIdNo AND ACCT_NO = :acctNo AND\n"
				+ "BL_TYP_CD = 'C' AND CURR_PRI_IND = 'C'";

		BL_ACCT_STAT_CD_SQL = "SELECT BL_ACCT_STAT_CD FROM " + jobConfig.getSchemaName()
				+ "BL_ACCT WHERE CUST_ID_NO = :custIdNo AND ACCT_NO = :acctNo";

		BL_ACCT_SQL = "SELECT count (*) FROM " + jobConfig.getSchemaName()
				+ "BL_ACCT WHERE CUST_ID_NO = :custIdNo AND ACCT_NO = :acctNo " + "AND SVC_OFFR_CD = 'POSPB'";

		log.debug("Acst787p job is started...");

		Acst787pModel acst787pModel = null;
		KeyValue keyValue = new KeyValue();
		KeyValue keyValue1 = new KeyValue();
		KeyValue keyValue2 = new KeyValue();
		KeyValue keyValue3 = new KeyValue();
		KeyValue keyValue4 = new KeyValue();
		Map<String, Object> compositeMap = new HashMap<>();
		CompositeDataModel cmp = new CompositeDataModel();
		CompositeFileWriterModel compositeFileWriterModel = new CompositeFileWriterModel();
		List<BatchGenericModel> keyValues = new ArrayList<>();
		if (item instanceof CompositeReaderModel) {

			List<BatchGenericModel> items = ((CompositeReaderModel) item).getItems();
			for (BatchGenericModel model : items) {
				if (model instanceof Acst787pModel) {
					log.info("model1: {} ", model);
					acst787pModel = (Acst787pModel) model;

					if (acst787pModel != null) {
						acst787pModel = processAcst787p(acst787pModel, jobName, namedJdbcTemplate);
						if (acst787pModel == null) {
							return null;
						}
						if(acst787pModel!=null && acst787pModel.getValidVisionInstance().equals("E")) {
							String eastFileName = jobConfig.getJobOutput().stream()
									.filter(x -> x.getSeqNo() == 0 || x.getSeqNo() == 1).findFirst().orElse(null)
									.getFileName();
							keyValue.setKey(eastFileName);
							keyValue.setValue(acst787pModel);
							keyValues.add(keyValue);

						} else if (acst787pModel!=null && acst787pModel.getValidVisionInstance().equals("W")) {
							String westFileName = jobConfig.getJobOutput().stream()
									.filter(x -> x.getSeqNo() == 0 || x.getSeqNo() == 2).findFirst().orElse(null)
									.getFileName();
							keyValue1.setKey(westFileName);
							keyValue1.setValue(acst787pModel);
							keyValues.add(keyValue1);

						} else if (acst787pModel!=null && acst787pModel.getValidVisionInstance().equals("N")) {
							String northFileName = jobConfig.getJobOutput().stream()
									.filter(x -> x.getSeqNo() == 0 || x.getSeqNo() == 3).findFirst().orElse(null)
									.getFileName();
							keyValue2.setKey(northFileName);
							keyValue2.setValue(acst787pModel);
							keyValues.add(keyValue2);
						} else if (acst787pModel!=null && acst787pModel.getValidVisionInstance().equals("VB2B")) {
							String vb2bFileName = jobConfig.getJobOutput().stream()
									.filter(x -> x.getSeqNo() == 0 || x.getSeqNo() == 4).findFirst().orElse(null)
									.getFileName();
							keyValue3.setKey(vb2bFileName);
							keyValue3.setValue(acst787pModel);
							keyValues.add(keyValue3);
						} else {
							String soloFileName = jobConfig.getJobOutput().stream()
									.filter(x -> x.getSeqNo() == 0 || x.getSeqNo() == 5).findFirst().orElse(null)
									.getFileName();
							keyValue4.setKey(soloFileName);
							keyValue4.setValue(acst787pModel);
							keyValues.add(keyValue4);
						}
					}
					compositeFileWriterModel.setItems(keyValues);
					compositeMap.put("file", compositeFileWriterModel);
				}
			}
		}

		log.debug("Acst787p job is ended...");

		cmp.setCompositeMap(compositeMap);
		return cmp;
	}


_________________________________________________________

To create an additional merged file that contains all processed data, you can follow this approach:

Steps to Modify Your Code

1. Continue adding individual files for each validVisionInstance, as you already do.


2. Create a new mergedFileKeyValue object to hold all records.


3. After processing all items, add the merged data to this file.




---

Modified Code Snippet

List<BatchGenericModel> keyValues = new ArrayList<>();
List<Acst787pModel> mergedData = new ArrayList<>(); // To store merged data

if (item instanceof CompositeReaderModel) {
    List<BatchGenericModel> items = ((CompositeReaderModel) item).getItems();
    for (BatchGenericModel model : items) {
        if (model instanceof Acst787pModel) {
            log.info("Processing model: {} ", model);
            Acst787pModel acst787pModel = (Acst787pModel) model;

            if (acst787pModel != null) {
                acst787pModel = processAcst787p(acst787pModel, jobName, namedJdbcTemplate);
                if (acst787pModel == null) {
                    return null;
                }
                
                // Store data in merged list
                mergedData.add(acst787pModel);
                
                String fileName;
                switch (acst787pModel.getValidVisionInstance()) {
                    case "E" -> fileName = jobConfig.getJobOutput().stream()
                            .filter(x -> x.getSeqNo() == 1)
                            .map(JobOutput::getFileName)
                            .findFirst()
                            .orElse("default_east.txt");
                    case "W" -> fileName = jobConfig.getJobOutput().stream()
                            .filter(x -> x.getSeqNo() == 2)
                            .map(JobOutput::getFileName)
                            .findFirst()
                            .orElse("default_west.txt");
                    case "N" -> fileName = jobConfig.getJobOutput().stream()
                            .filter(x -> x.getSeqNo() == 3)
                            .map(JobOutput::getFileName)
                            .findFirst()
                            .orElse("default_north.txt");
                    case "VB2B" -> fileName = jobConfig.getJobOutput().stream()
                            .filter(x -> x.getSeqNo() == 4)
                            .map(JobOutput::getFileName)
                            .findFirst()
                            .orElse("default_vb2b.txt");
                    default -> fileName = jobConfig.getJobOutput().stream()
                            .filter(x -> x.getSeqNo() == 5)
                            .map(JobOutput::getFileName)
                            .findFirst()
                            .orElse("default_solo.txt");
                }

                KeyValue keyValue = new KeyValue();
                keyValue.setKey(fileName);
                keyValue.setValue(acst787pModel);
                keyValues.add(keyValue);
            }
        }
    }
}

// Add merged data to a new file
String mergedFileName = jobConfig.getJobOutput().stream()
        .filter(x -> x.getSeqNo() == 6)  // Assuming 6 is the sequence number for merged file
        .map(JobOutput::getFileName)
        .findFirst()
        .orElse("default_merged.txt");

KeyValue mergedFileKeyValue = new KeyValue();
mergedFileKeyValue.setKey(mergedFileName);
mergedFileKeyValue.setValue(mergedData);  // Add full merged data
keyValues.add(mergedFileKeyValue);

// Create composite output
CompositeFileWriterModel compositeFileWriterModel = new CompositeFileWriterModel();
compositeFileWriterModel.setItems(keyValues);

Map<String, Object> compositeMap = new HashMap<>();
compositeMap.put("file", compositeFileWriterModel);

CompositeDataModel cmp = new CompositeDataModel();
cmp.setCompositeMap(compositeMap);

log.debug("Acst787p job is ended...");
return cmp;


---

Explanation of the Changes

✔ Each item is still assigned to its respective file based on validVisionInstance.
✔ New list mergedData collects all acst787pModel objects.
✔ After processing, a new KeyValue object (mergedFileKeyValue) stores all records in a merged file.
✔ mergedFileName is retrieved dynamically based on a new sequence (seqNo == 6).
✔ The merged file is added to the final output (compositeMap).

This approach ensures that:

You still get individual files per validVisionInstance.

A new merged file contains all processed records in a single place.



---

Next Steps

1. If seqNo == 6 is not already defined for the merged file in jobConfig.getJobOutput(), add it.


2. If the merged file format differs from individual files, adjust the KeyValue object accordingly.


3. Test the batch process with different datasets to ensure all cases are handled correctly.



Would you like any refinements, such as handling duplicates or specific formatting in the merged file?


